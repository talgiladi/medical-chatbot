{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/talgiladi/medical-chatbot/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install langchain-pinecone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "-atHWPAuz9YC"
      },
      "outputs": [],
      "source": [
        "from load_dotenv import load_dotenv\n",
        "import os\n",
        "load_dotenv()\n",
        "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import Pinecone\n",
        "\n",
        "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.llms import ctransformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "PINECONE_API_ENV=\"\"\n",
        "\n",
        "HOST=\"https://medical-chatbot-fn63rwe.svc.aped-4627-b74a.pinecone.io\"\n",
        "INDEX=\"quickstart\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_pdf(directory: str):\n",
        "    loader = DirectoryLoader(directory,\n",
        "                    glob=\"*.pdf\",\n",
        "                    loader_cls=PyPDFLoader)\n",
        "    docs = loader.load()\n",
        "    return docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "docs = load_pdf(directory=\"data/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def text_split(documents: list):\n",
        "    splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size = 500,\n",
        "        chunk_overlap = 50\n",
        "    )\n",
        "    chunks = splitter.split_documents(documents=documents)\n",
        "    return chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [],
      "source": [
        "text_chunks = text_split(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "def download_hugging_face_embeddings():\n",
        "    embeddings = HuggingFaceEmbeddings(\n",
        "        model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "    )\n",
        "    return embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [],
      "source": [
        "embeddings = download_hugging_face_embeddings()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# update/use the pinecone index with our documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_pinecone import PineconeVectorStore\n",
        "docsearch = None\n",
        "index_name = \"medical-chatbot2\"\n",
        "has_existing_index = True\n",
        "if (has_existing_index):\n",
        "    docsearch = PineconeVectorStore.from_existing_index(\n",
        "        index_name = index_name, \n",
        "        embedding=embeddings)\n",
        "else:\n",
        "    #upload the data now\n",
        "    batch_size = 300  # Adjust this value based on your requirement\n",
        "    chunks = [t.page_content for t in text_chunks]\n",
        "    \n",
        "    # Split the chunks array into smaller arrays\n",
        "    chunks_small = [chunks[i:i + batch_size] for i in range(0, len(chunks), batch_size)]\n",
        "  \n",
        "    # Loop through each small array and upload it\n",
        "    for i, small_chunk in enumerate(chunks_small):\n",
        "        print(f\"Uploading batch {i+1} out of {len(chunks_small)}\")\n",
        "        docsearch=PineconeVectorStore.from_texts(small_chunk, embeddings, index_name=index_name)\n",
        "        print(f\"Finished uploading batch {i+1}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {},
      "outputs": [],
      "source": [
        "#%pip install --upgrade --quiet  langchain-pinecone langchain-openai langchain\n",
        "# from langchain_pinecone import PineconeVectorStore\n",
        "\n",
        "# index_name = \"medical-chatbot2\"\n",
        "\n",
        "# docsearch = PineconeVectorStore.from_existing_index(embedding= embeddings, index_name=index_name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# test the index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test1 = docsearch.similarity_search(\"allergies\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# create the prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "\n",
        "prompt_template = \"\"\"you are a medical chat bot. If you don't know the answer, say that you don't know, don't try to make things up.\n",
        "    context:{context}\n",
        "    question:{question}\n",
        "    \"\"\"\n",
        "prompt=PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
        "chain_type_kwargs={\"prompt\": prompt}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# create the llm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.llms import CTransformers\n",
        "llm=CTransformers(model=\"model/llama-2-7b-chat.ggmlv3.q4_0.bin\",\n",
        "                  model_type=\"llama\",\n",
        "                  config={'max_new_tokens':512,\n",
        "                          'temperature':0.8})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# now... the QARetrivevel didn't work, so I just did the similarity search, and manually combined the results, and sent them to the LLM as context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.chains import LLMChain\n",
        "#the user query:\n",
        "query = \"tell my a few words about allergies\"\n",
        "\n",
        "#retrieve the docs from the vector store\n",
        "retriever = docsearch.as_retriever()\n",
        "matched_docs = docsearch.similarity_search(query=  query, k = 3)\n",
        "\n",
        "#combine them\n",
        "context = \"\"\n",
        "for i, d in enumerate(test1):\n",
        "    context = context + (f\"\\n## Document {i}\\n\")\n",
        "    context = context + (d.page_content)\n",
        "\n",
        "#create the chain\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# create the chain and run it using the user query and the context from the documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {},
      "outputs": [],
      "source": [
        "chain = LLMChain(llm = llm, prompt = prompt)\n",
        "result = chain.run(question= query, context= context, verbose = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " answer:Allergy is an abnormal reaction to substances that are normally harmless to most people. these substances, known as allergen, can trigger a wide range of symptoms including sneezing, runny nose, congestion, itchy eyes and throat, coughing, wheezing, and skin rashes. Common allergens include pollen, dust, mold, pet dander, insect stings, and certain foods such as nuts, fish, and milk.\n"
          ]
        }
      ],
      "source": [
        "print(result)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNP7Ljv1LF+xnyRkUZqnTZl",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
